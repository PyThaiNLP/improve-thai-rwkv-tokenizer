{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce1e4bb-4169-451a-be07-1253941e7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################################################################\n",
      "\n",
      "This tokenizer is not used in any RWKV models yet. I plan to use it for the future multilang RWKV models.\n",
      "\n",
      "Benefits:\n",
      "\n",
      "* Good support of most languages, from European to CJK to Arabic and Hindi and more.\n",
      "\n",
      "* Clean vocab. Good for code too. Vocab size = 65536 (use 0 for <|endoftext|>).\n",
      "\n",
      "* Good at numbers: the numerical tokens are '0'~'9', '10'~'99', ' 0'~' 9', ' 10'~' 99'.\n",
      "\n",
      "* Very easy tokenization:\n",
      "\n",
      "** The input text must be in UTF-8.\n",
      "\n",
      "** Greedy encoding: always pick the longest (in bytes) token (with the highest id) that matches your UTF-8 bytes.\n",
      "\n",
      "* The tokenization result is surprisingly good, because the vocab respects word boundaries and UTF-8 boundaries.\n",
      "\n",
      "For 10x faster speed:\n",
      "mypyc rwkv_tokenizer.py\n",
      "python3 -c \"import rwkv_tokenizer\"\n",
      "\n",
      "#######################################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, random\n",
    "\n",
    "print('''\n",
    "#######################################################################################################################\n",
    "\n",
    "This tokenizer is not used in any RWKV models yet. I plan to use it for the future multilang RWKV models.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "* Good support of most languages, from European to CJK to Arabic and Hindi and more.\n",
    "\n",
    "* Clean vocab. Good for code too. Vocab size = 65536 (use 0 for <|endoftext|>).\n",
    "\n",
    "* Good at numbers: the numerical tokens are '0'~'9', '10'~'99', ' 0'~' 9', ' 10'~' 99'.\n",
    "\n",
    "* Very easy tokenization:\n",
    "\n",
    "** The input text must be in UTF-8.\n",
    "\n",
    "** Greedy encoding: always pick the longest (in bytes) token (with the highest id) that matches your UTF-8 bytes.\n",
    "\n",
    "* The tokenization result is surprisingly good, because the vocab respects word boundaries and UTF-8 boundaries.\n",
    "\n",
    "For 10x faster speed:\n",
    "mypyc rwkv_tokenizer.py\n",
    "python3 -c \"import rwkv_tokenizer\"\n",
    "\n",
    "#######################################################################################################################\n",
    "''')\n",
    "\n",
    "########################################################################################################\n",
    "# Tokenizer #1 (reference, naive, slow)\n",
    "########################################################################################################\n",
    "\n",
    "class RWKV_TOKENIZER():\n",
    "    table: list[list[list[bytes]]]\n",
    "    good: list[set[int]]\n",
    "    wlen: list[int]\n",
    "    def __init__(self, file_name):\n",
    "        self.idx2token = {}\n",
    "        sorted = [] # must be already sorted\n",
    "        lines = open(file_name, \"r\", encoding=\"utf-8\").readlines()\n",
    "        for l in lines:\n",
    "            idx = int(l[:l.index(' ')])\n",
    "            x = eval(l[l.index(' '):l.rindex(' ')])\n",
    "            x = x.encode(\"utf-8\") if isinstance(x, str) else x\n",
    "            assert isinstance(x, bytes)\n",
    "            assert len(x) == int(l[l.rindex(' '):])\n",
    "            sorted += [x]\n",
    "            self.idx2token[idx] = x\n",
    "\n",
    "        self.token2idx = {}\n",
    "        for k, v in self.idx2token.items():\n",
    "            self.token2idx[v] = int(k)\n",
    "\n",
    "        # precompute some tables for fast matching\n",
    "        self.table = [[[] for j in range(256)] for i in range(256)]\n",
    "        self.good = [set() for i in range(256)]\n",
    "        self.wlen = [0 for i in range(256)]\n",
    "\n",
    "        for i in reversed(range(len(sorted))): # reverse order - match longer tokens first\n",
    "            s = sorted[i]\n",
    "            if len(s) >= 2:\n",
    "                s0 = int(s[0])\n",
    "                s1 = int(s[1])\n",
    "                self.table[s0][s1] += [s]\n",
    "                self.wlen[s0] = max(self.wlen[s0], len(s))\n",
    "                self.good[s0].add(s1)\n",
    "\n",
    "    def encodeBytes(self, src: bytes) -> list[int]:\n",
    "        src_len: int = len(src)\n",
    "        tokens: list[int] = []\n",
    "        i: int = 0\n",
    "        while i < src_len:\n",
    "            s: bytes = src[i : i + 1]\n",
    "\n",
    "            if i < src_len - 1:\n",
    "                s1: int = int(src[i + 1])\n",
    "                s0: int = int(src[i])\n",
    "                if s1 in self.good[s0]:\n",
    "                    sss: bytes = src[i : i + self.wlen[s0]]\n",
    "                    try:\n",
    "                        s = next(filter(sss.startswith, self.table[s0][s1]))\n",
    "                    except:\n",
    "                        pass\n",
    "            tokens.append(self.token2idx[s])\n",
    "            i += len(s)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def decodeBytes(self, tokens):\n",
    "        return b''.join(map(lambda i: self.idx2token[i], tokens))\n",
    "\n",
    "    def encode(self, src: str):\n",
    "        return self.encodeBytes(src.encode(\"utf-8\"))\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return self.decodeBytes(tokens).decode('utf-8')\n",
    "\n",
    "    def printTokens(self, tokens):\n",
    "        for i in tokens:\n",
    "            s = self.idx2token[i]\n",
    "            try:\n",
    "                s = s.decode('utf-8')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'{repr(s)}{i}', end=' ')\n",
    "            # print(repr(s), i)\n",
    "        print()\n",
    "\n",
    "########################################################################################################\n",
    "# Tokenizer #2 (trie, faster) https://github.com/TkskKurumi/ChatRWKV-TRIE-Tokenizer\n",
    "########################################################################################################\n",
    "\n",
    "class TRIE:\n",
    "    __slots__ = tuple(\"ch,to,values,front\".split(\",\"))\n",
    "    to:list\n",
    "    values:set\n",
    "    def __init__(self, front=None, ch=None):\n",
    "        self.ch = ch\n",
    "        self.to = [None for ch in range(256)]\n",
    "        self.values = set()\n",
    "        self.front = front\n",
    "\n",
    "    def __repr__(self):\n",
    "        fr = self\n",
    "        ret = []\n",
    "        while(fr!=None):\n",
    "            if(fr.ch!=None):\n",
    "                ret.append(fr.ch)\n",
    "            fr = fr.front\n",
    "        return \"<TRIE %s %s>\"%(ret[::-1], self.values)\n",
    "    \n",
    "    def add(self, key:bytes, idx:int=0, val=None):\n",
    "        if(idx == len(key)):\n",
    "            if(val is None):\n",
    "                val = key\n",
    "            self.values.add(val)\n",
    "            return self\n",
    "        ch = key[idx]\n",
    "        if(self.to[ch] is None):\n",
    "            self.to[ch] = TRIE(front=self, ch=ch)\n",
    "        return self.to[ch].add(key, idx=idx+1, val=val)\n",
    "    \n",
    "    def find_longest(self, key:bytes, idx:int=0):\n",
    "        u:TRIE = self\n",
    "        ch:int = key[idx]\n",
    "        \n",
    "        while(u.to[ch] is not None):\n",
    "            u = u.to[ch]\n",
    "            idx += 1\n",
    "            if(u.values):\n",
    "                ret = idx, u, u.values\n",
    "            if(idx==len(key)):\n",
    "                break\n",
    "            ch = key[idx]\n",
    "        return ret\n",
    "\n",
    "class TRIE_TOKENIZER():\n",
    "    def __init__(self, file_name):\n",
    "        self.idx2token = {}\n",
    "        sorted = [] # must be already sorted\n",
    "        with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "        for l in lines:\n",
    "            idx = int(l[:l.index(' ')])\n",
    "            x = eval(l[l.index(' '):l.rindex(' ')])\n",
    "            x = x.encode(\"utf-8\") if isinstance(x, str) else x\n",
    "            assert isinstance(x, bytes)\n",
    "            assert len(x) == int(l[l.rindex(' '):])\n",
    "            sorted += [x]\n",
    "            self.idx2token[idx] = x\n",
    "\n",
    "        self.token2idx = {}\n",
    "        for k,v in self.idx2token.items():\n",
    "            self.token2idx[v] = int(k)\n",
    "\n",
    "        self.root = TRIE()\n",
    "        for t, i in self.token2idx.items():\n",
    "            _ = self.root.add(t, val=(t, i))\n",
    "\n",
    "    def encodeBytes(self, src:bytes):\n",
    "        idx:int = 0\n",
    "        tokens = []\n",
    "        while (idx < len(src)):\n",
    "            _idx:int = idx\n",
    "            idx, _, values = self.root.find_longest(src, idx)\n",
    "            assert(idx != _idx)\n",
    "            _, token = next(iter(values))            \n",
    "            tokens.append(token)\n",
    "        return tokens\n",
    "\n",
    "    def decodeBytes(self, tokens):\n",
    "        return b''.join(map(lambda i: self.idx2token[i], tokens))\n",
    "\n",
    "    def encode(self, src):\n",
    "        return self.encodeBytes(src.encode(\"utf-8\"))\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return self.decodeBytes(tokens).decode('utf-8')\n",
    "\n",
    "    def printTokens(self, tokens):\n",
    "        for i in tokens:\n",
    "            s = self.idx2token[i]\n",
    "            try:\n",
    "                s = s.decode('utf-8')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'{repr(s)}{i}', end=' ')\n",
    "        print()\n",
    "\n",
    "########################################################################################################\n",
    "# Demo\n",
    "########################################################################################################\n",
    "\n",
    "TOKENIZER = RWKV_TOKENIZER('rwkv_vocab_v20230424.txt')\n",
    "TRIE_TEST = TRIE_TOKENIZER('rwkv_vocab_v20230424.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7596e9f-5b75-407e-bd8d-0b23ce6d3017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ภาษาไทย หรือ ภาษาไทยกลาง เป็นภาษาในกลุ่มภาษาไท สาขาย่อยเชียงแสน ซึ่งเป็นกลุ่มย่อยของตระกูลภาษาขร้า-ไท และเป็นภาษาราชการ และภาษาประจำชาติของประเทศไทย[3][4] มีการสันนิษฐานว่าภาษาในตระกูลนี้มีถิ่นกำเนิดจากทางตอนใต้ของประเทศจีน และนักภาษาศาสตร์บางส่วนเสนอว่า ภาษาไทยน่าจะมีความเชื่อมโยงกับตระกูลภาษาออสโตร-เอเชียติก ตระกูลภาษาออสโตรนีเซียน และตระกูลภาษาจีน-ทิเบต\n",
      "ภาษาไทยเป็นภาษาที่มีระดับเสียงของคำแน่นอนหรือวรรณยุกต์เช่นเดียวกับภาษาจีน และออกเสียงแยกคำต่อคำ\n",
      "ภาษาไทยปรากฏครั้งแรกในพุทธศักราช 1826 โดยพ่อขุนรามคำแหง และปรากฏอย่างสากลและใช้ในงานของราชการ เมื่อวันที่ 31 มีนาคม พุทธศักราช 2476 ด้วยการก่อตั้งสำนักงานราชบัณฑิตยสภาขึ้น และปฏิรูปภาษาไทย พุทธศักราช 2485\n",
      "\n",
      "659 chars\n",
      "\n",
      "'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ไ'9643 'ท'9612 'ย'9621 ' '33 'ห'9628 'ร'9622 'ื'9636 'อ'9629 ' '33 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ไ'9643 'ท'9612 'ย'9621 'ก'9601 'ล'9623 'าง'43264 ' เ'22891 'ป'9616 '็'9644 'น'9614 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ใ'9642 'น'9614 'ก'9601 'ล'9623 'ุ'9637 '่'9645 'ม'9620 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ไ'9643 'ท'9612 ' '33 'ส'9627 'า'9632 'ข'9602 'า'9632 'ย'9621 '่'9645 'อ'9629 'ย'9621 'เ'9639 'ช'9606 'ี'9635 'ย'9621 'ง'9604 'แ'9640 'ส'9627 'น'9614 ' '33 b'\\xe0\\xb8'2992 b'\\x8b'140 b'\\xe0\\xb8'2992 b'\\xb6'183 '่'9645 'ง'9604 'เ'9639 'ป'9616 '็'9644 'น'9614 'ก'9601 'ล'9623 'ุ'9637 '่'9645 'ม'9620 'ย'9621 '่'9645 'อ'9629 'ย'9621 'ข'9602 'อง'43263 'ต'9610 'ระ'43262 'ก'9601 'ู'9638 'ล'9623 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ข'9602 'ร'9622 '้า'43269 '-'46 'ไ'9643 'ท'9612 ' '33 'แ'9640 'ล'9623 'ะ'9630 'เ'9639 'ป'9616 '็'9644 'น'9614 'ภ'9619 'า'9632 'ษ'9626 'าร'43265 'า'9632 'ช'9606 'การ'58513 ' '33 'แ'9640 'ล'9623 'ะ'9630 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ป'9616 'ระ'43262 'จ'9605 'ำ'9633 'ช'9606 'า'9632 'ต'9610 'ิ'9634 'ข'9602 'อง'43263 'ป'9616 'ระ'43262 'เ'9639 'ท'9612 'ศ'9625 'ไ'9643 'ท'9612 'ย'9621 '['92 '3'52 ']['1695 '4'53 ']'94 ' '33 'ม'9620 'ี'9635 'การ'58513 'ส'9627 'ั'9631 'น'9614 'น'9614 'ิ'9634 'ษ'9626 b'\\xe0\\xb8'2992 b'\\x90'145 'า'9632 'น'9614 'ว'9624 '่'9645 'า'9632 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ใ'9642 'น'9614 'ต'9610 'ระ'43262 'ก'9601 'ู'9638 'ล'9623 'น'9614 'ี'9635 '้'9646 'ม'9620 'ี'9635 'ถ'9611 'ิ'9634 '่'9645 'น'9614 'ก'9601 'ำ'9633 'เ'9639 'น'9614 'ิ'9634 'ด'9609 'จ'9605 'า'9632 'ก'9601 'ท'9612 'าง'43264 'ต'9610 'อ'9629 'น'9614 'ใ'9642 'ต'9610 '้'9646 'ข'9602 'อง'43263 'ป'9616 'ระ'43262 'เ'9639 'ท'9612 'ศ'9625 'จ'9605 'ี'9635 'น'9614 ' '33 'แ'9640 'ล'9623 'ะ'9630 'น'9614 'ั'9631 'ก'9601 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ศ'9625 'า'9632 'ส'9627 'ต'9610 'ร'9622 '์'9647 'บ'9615 'าง'43264 'ส'9627 '่'9645 'ว'9624 'น'9614 'เ'9639 'ส'9627 'น'9614 'อ'9629 'ว'9624 '่'9645 'า'9632 ' '33 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ไ'9643 'ท'9612 'ย'9621 'น'9614 '่'9645 'า'9632 'จ'9605 'ะ'9630 'ม'9620 'ี'9635 'ค'9603 'ว'9624 'า'9632 'ม'9620 'เ'9639 'ช'9606 'ื่'43267 'อ'9629 'ม'9620 'โ'9641 'ย'9621 'ง'9604 'ก'9601 'ั'9631 'บ'9615 'ต'9610 'ระ'43262 'ก'9601 'ู'9638 'ล'9623 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'อ'9629 'อ'9629 'ส'9627 'โ'9641 'ต'9610 'ร'9622 '-'46 'เ'9639 'อ'9629 'เ'9639 'ช'9606 'ี'9635 'ย'9621 'ต'9610 'ิ'9634 'ก'9601 ' '33 'ต'9610 'ระ'43262 'ก'9601 'ู'9638 'ล'9623 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'อ'9629 'อ'9629 'ส'9627 'โ'9641 'ต'9610 'ร'9622 'น'9614 'ี'9635 'เ'9639 b'\\xe0\\xb8'2992 b'\\x8b'140 'ี'9635 'ย'9621 'น'9614 ' '33 'แ'9640 'ล'9623 'ะ'9630 'ต'9610 'ระ'43262 'ก'9601 'ู'9638 'ล'9623 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'จ'9605 'ี'9635 'น'9614 '-'46 'ท'9612 'ิ'9634 'เ'9639 'บ'9615 'ต'9610 '\\n'11 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ไ'9643 'ท'9612 'ย'9621 'เ'9639 'ป'9616 '็'9644 'น'9614 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ที่'58514 'ม'9620 'ี'9635 'ระ'43262 'ด'9609 'ั'9631 'บ'9615 'เ'9639 'ส'9627 'ี'9635 'ย'9621 'ง'9604 'ข'9602 'อง'43263 'ค'9603 'ำ'9633 'แ'9640 'น'9614 '่'9645 'น'9614 'อ'9629 'น'9614 'ห'9628 'ร'9622 'ื'9636 'อ'9629 'ว'9624 'ร'9622 'ร'9622 'ณ'9608 'ย'9621 'ุ'9637 'ก'9601 'ต'9610 '์'9647 'เ'9639 'ช'9606 '่'9645 'น'9614 'เ'9639 'ด'9609 'ี'9635 'ย'9621 'ว'9624 'ก'9601 'ั'9631 'บ'9615 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'จ'9605 'ี'9635 'น'9614 ' '33 'แ'9640 'ล'9623 'ะ'9630 'อ'9629 'อ'9629 'ก'9601 'เ'9639 'ส'9627 'ี'9635 'ย'9621 'ง'9604 'แ'9640 'ย'9621 'ก'9601 'ค'9603 'ำ'9633 'ต'9610 '่'9645 'อ'9629 'ค'9603 'ำ'9633 '\\n'11 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ไ'9643 'ท'9612 'ย'9621 'ป'9616 'ร'9622 'า'9632 'ก'9601 b'\\xe0\\xb8'2992 b'\\x8f'144 'ค'9603 'ร'9622 'ั'9631 '้'9646 'ง'9604 'แ'9640 'ร'9622 'ก'9601 'ใ'9642 'น'9614 'พ'9618 'ุ'9637 'ท'9612 'ธ'9613 'ศ'9625 'ั'9631 'ก'9601 'ร'9622 'า'9632 'ช'9606 ' 18'3491 '26'646 ' '33 'โ'9641 'ด'9609 'ย'9621 'พ'9618 '่'9645 'อ'9629 'ข'9602 'ุ'9637 'น'9614 'ร'9622 'า'9632 'ม'9620 'ค'9603 'ำ'9633 'แ'9640 'ห'9628 'ง'9604 ' '33 'แ'9640 'ล'9623 'ะ'9630 'ป'9616 'ร'9622 'า'9632 'ก'9601 b'\\xe0\\xb8'2992 b'\\x8f'144 'อ'9629 'ย'9621 '่'9645 'าง'43264 'ส'9627 'า'9632 'ก'9601 'ล'9623 'แ'9640 'ล'9623 'ะ'9630 'ใ'9642 'ช'9606 '้'9646 'ใ'9642 'น'9614 'ง'9604 'า'9632 'น'9614 'ข'9602 'อง'43263 'ร'9622 'า'9632 'ช'9606 'การ'58513 ' เ'22891 'ม'9620 'ื่'43267 'อ'9629 'ว'9624 'ั'9631 'น'9614 'ที่'58514 ' 31'3504 ' '33 'ม'9620 'ี'9635 'น'9614 'า'9632 'ค'9603 'ม'9620 ' '33 'พ'9618 'ุ'9637 'ท'9612 'ธ'9613 'ศ'9625 'ั'9631 'ก'9601 'ร'9622 'า'9632 'ช'9606 ' 24'3497 '76'696 ' '33 'ด'9609 '้'9646 'ว'9624 'ย'9621 'การ'58513 'ก'9601 '่'9645 'อ'9629 'ต'9610 'ั'9631 '้'9646 'ง'9604 'ส'9627 'ำ'9633 'น'9614 'ั'9631 'ก'9601 'ง'9604 'า'9632 'น'9614 'ร'9622 'า'9632 'ช'9606 'บ'9615 'ั'9631 'ณ'9608 b'\\xe0\\xb8'2992 b'\\x91'146 'ิ'9634 'ต'9610 'ย'9621 'ส'9627 'ภ'9619 'า'9632 'ข'9602 b'\\xe0\\xb8'2992 b'\\xb6'183 '้'9646 'น'9614 ' '33 'แ'9640 'ล'9623 'ะ'9630 'ป'9616 b'\\xe0\\xb8'2992 b'\\x8f'144 'ิ'9634 'ร'9622 'ู'9638 'ป'9616 'ภ'9619 'า'9632 'ษ'9626 'า'9632 'ไ'9643 'ท'9612 'ย'9621 ' '33 'พ'9618 'ุ'9637 'ท'9612 'ธ'9613 'ศ'9625 'ั'9631 'ก'9601 'ร'9622 'า'9632 'ช'9606 ' 24'3497 '85'705 \n",
      "\n",
      "620 tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src1 = '''ภาษาไทย หรือ ภาษาไทยกลาง เป็นภาษาในกลุ่มภาษาไท สาขาย่อยเชียงแสน ซึ่งเป็นกลุ่มย่อยของตระกูลภาษาขร้า-ไท และเป็นภาษาราชการ และภาษาประจำชาติของประเทศไทย[3][4] มีการสันนิษฐานว่าภาษาในตระกูลนี้มีถิ่นกำเนิดจากทางตอนใต้ของประเทศจีน และนักภาษาศาสตร์บางส่วนเสนอว่า ภาษาไทยน่าจะมีความเชื่อมโยงกับตระกูลภาษาออสโตร-เอเชียติก ตระกูลภาษาออสโตรนีเซียน และตระกูลภาษาจีน-ทิเบต\n",
    "ภาษาไทยเป็นภาษาที่มีระดับเสียงของคำแน่นอนหรือวรรณยุกต์เช่นเดียวกับภาษาจีน และออกเสียงแยกคำต่อคำ\n",
    "ภาษาไทยปรากฏครั้งแรกในพุทธศักราช 1826 โดยพ่อขุนรามคำแหง และปรากฏอย่างสากลและใช้ในงานของราชการ เมื่อวันที่ 31 มีนาคม พุทธศักราช 2476 ด้วยการก่อตั้งสำนักงานราชบัณฑิตยสภาขึ้น และปฏิรูปภาษาไทย พุทธศักราช 2485'''\n",
    "\n",
    "print(src1)\n",
    "print(f'\\n{len(src1)} chars')\n",
    "tokens = TOKENIZER.encode(src1)\n",
    "assert TOKENIZER.decode(tokens) == src1\n",
    "print()\n",
    "TOKENIZER.printTokens(tokens)\n",
    "print(f'\\n{len(tokens)} tokens\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcde151c-f184-45ae-bb04-9470c9a81489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ๏ แผ่นดินฮั่นเสื่อมโทรมแสนสังเวช  พระปกเกศกองบู๊กู้ขึ้นใหม่\n",
      "  สิบสองกษัตริย์ก่อนหน้าแลถัดไป       สององค์ไซร้โง่เขลาเบาปัญญา\n",
      "    ทรงนับถือขันทีเป็นที่พึ่ง           บ้านเมืองจึงวิปริตเป็นนักหนา\n",
      "  โฮจิ๋นเรียกทัพทั่วหัวเมืองมา         หมายจะฆ่ามดชั่วตัวสำคัญ\n",
      "    เหมือนขับไสไล่เสือจากเคหา      รับหมาป่าเข้ามาเลยอาสัญ\n",
      "  ฝ่ายอ้องอุ้นยุแยกให้แตกกัน          ใช้สาวนั้นเป็นชนวนชื่นชวนใจ\n",
      "    พลันลิฉุยกุยกีกลับก่อเหตุ          ช่างอาเพศจริงหนาฟ้าร้องไห้\n",
      "  ต้องรบราฆ่าฟันจนบรรลัย           ฤๅหาใครค้ำชูกู้บรรลังก์ ฯ\n",
      "\n",
      "512 chars\n",
      "\n",
      "'    '19250 b'\\xe0\\xb9'2993 b'\\x8f'144 ' '33 'แ'9640 'ผ'9617 '่'9645 'น'9614 'ด'9609 'ิ'9634 'น'9614 b'\\xe0\\xb8'2992 b'\\xae'175 'ั'9631 '่'9645 'น'9614 'เ'9639 'ส'9627 'ื่'43267 'อ'9629 'ม'9620 'โ'9641 'ท'9612 'ร'9622 'ม'9620 'แ'9640 'ส'9627 'น'9614 'ส'9627 'ั'9631 'ง'9604 'เ'9639 'ว'9624 'ช'9606 '  '267 'พ'9618 'ระ'43262 'ป'9616 'ก'9601 'เ'9639 'ก'9601 'ศ'9625 'ก'9601 'อง'43263 'บ'9615 'ู'9638 b'\\xe0\\xb9'2993 b'\\x8a'139 'ก'9601 'ู'9638 '้'9646 'ข'9602 b'\\xe0\\xb8'2992 b'\\xb6'183 '้'9646 'น'9614 'ใ'9642 'ห'9628 'ม'9620 '่'9645 '\\n  '3331 'ส'9627 'ิ'9634 'บ'9615 'ส'9627 'อง'43263 'ก'9601 'ษ'9626 'ั'9631 'ต'9610 'ร'9622 'ิ'9634 'ย'9621 '์'9647 'ก'9601 '่'9645 'อ'9629 'น'9614 'ห'9628 'น'9614 '้า'43269 'แ'9640 'ล'9623 'ถ'9611 'ั'9631 'ด'9609 'ไ'9643 'ป'9616 '       '43914 'ส'9627 'อง'43263 'อง'43263 'ค'9603 '์'9647 'ไ'9643 b'\\xe0\\xb8'2992 b'\\x8b'140 'ร'9622 '้'9646 'โ'9641 'ง'9604 '่'9645 'เ'9639 'ข'9602 'ล'9623 'า'9632 'เ'9639 'บ'9615 'า'9632 'ป'9616 'ั'9631 'ญ'9607 'ญ'9607 'า'9632 '\\n    '28352 'ท'9612 'ร'9622 'ง'9604 'น'9614 'ั'9631 'บ'9615 'ถ'9611 'ื'9636 'อ'9629 'ข'9602 'ั'9631 'น'9614 'ท'9612 'ี'9635 'เ'9639 'ป'9616 '็'9644 'น'9614 'ที่'58514 'พ'9618 b'\\xe0\\xb8'2992 b'\\xb6'183 '่'9645 'ง'9604 '           '61274 'บ'9615 '้า'43269 'น'9614 'เ'9639 'ม'9620 'ื'9636 'อง'43263 'จ'9605 b'\\xe0\\xb8'2992 b'\\xb6'183 'ง'9604 'ว'9624 'ิ'9634 'ป'9616 'ร'9622 'ิ'9634 'ต'9610 'เ'9639 'ป'9616 '็'9644 'น'9614 'น'9614 'ั'9631 'ก'9601 'ห'9628 'น'9614 'า'9632 '\\n  '3331 'โ'9641 b'\\xe0\\xb8'2992 b'\\xae'175 'จ'9605 'ิ'9634 b'\\xe0\\xb9'2993 b'\\x8b'140 'น'9614 'เ'9639 'ร'9622 'ี'9635 'ย'9621 'ก'9601 'ท'9612 'ั'9631 'พ'9618 'ท'9612 'ั'9631 '่'9645 'ว'9624 'ห'9628 'ั'9631 'ว'9624 'เ'9639 'ม'9620 'ื'9636 'อง'43263 'ม'9620 'า'9632 '         '54810 'ห'9628 'ม'9620 'า'9632 'ย'9621 'จ'9605 'ะ'9630 b'\\xe0\\xb8'2992 b'\\x86'135 '่'9645 'า'9632 'ม'9620 'ด'9609 'ช'9606 'ั'9631 '่'9645 'ว'9624 'ต'9610 'ั'9631 'ว'9624 'ส'9627 'ำ'9633 'ค'9603 'ั'9631 'ญ'9607 '\\n    '28352 'เ'9639 'ห'9628 'ม'9620 'ื'9636 'อ'9629 'น'9614 'ข'9602 'ั'9631 'บ'9615 'ไ'9643 'ส'9627 'ไ'9643 'ล'9623 '่'9645 'เ'9639 'ส'9627 'ื'9636 'อ'9629 'จ'9605 'า'9632 'ก'9601 'เ'9639 'ค'9603 'ห'9628 'า'9632 '      '36216 'ร'9622 'ั'9631 'บ'9615 'ห'9628 'ม'9620 'า'9632 'ป'9616 '่'9645 'า'9632 'เ'9639 'ข'9602 '้า'43269 'ม'9620 'า'9632 'เ'9639 'ล'9623 'ย'9621 'อ'9629 'า'9632 'ส'9627 'ั'9631 'ญ'9607 '\\n  '3331 b'\\xe0\\xb8'2992 b'\\x9d'158 '่'9645 'า'9632 'ย'9621 'อ'9629 '้'9646 'อง'43263 'อ'9629 'ุ'9637 '้'9646 'น'9614 'ย'9621 'ุ'9637 'แ'9640 'ย'9621 'ก'9601 'ใ'9642 'ห'9628 '้'9646 'แ'9640 'ต'9610 'ก'9601 'ก'9601 'ั'9631 'น'9614 '          '58655 'ใ'9642 'ช'9606 '้'9646 'ส'9627 'า'9632 'ว'9624 'น'9614 'ั'9631 '้'9646 'น'9614 'เ'9639 'ป'9616 '็'9644 'น'9614 'ช'9606 'น'9614 'ว'9624 'น'9614 'ช'9606 'ื่'43267 'น'9614 'ช'9606 'ว'9624 'น'9614 'ใ'9642 'จ'9605 '\\n    '28352 'พ'9618 'ล'9623 'ั'9631 'น'9614 'ล'9623 'ิ'9634 b'\\xe0\\xb8'2992 b'\\x89'138 'ุ'9637 'ย'9621 'ก'9601 'ุ'9637 'ย'9621 'ก'9601 'ี'9635 'ก'9601 'ล'9623 'ั'9631 'บ'9615 'ก'9601 '่'9645 'อ'9629 'เ'9639 'ห'9628 'ต'9610 'ุ'9637 '          '58655 'ช'9606 '่'9645 'าง'43264 'อ'9629 'า'9632 'เ'9639 'พ'9618 'ศ'9625 'จ'9605 'ร'9622 'ิ'9634 'ง'9604 'ห'9628 'น'9614 'า'9632 b'\\xe0\\xb8'2992 b'\\x9f'160 '้า'43269 'ร'9622 '้'9646 'อง'43263 'ไ'9643 'ห'9628 '้'9646 '\\n  '3331 'ต'9610 '้'9646 'อง'43263 'ร'9622 'บ'9615 'ร'9622 'า'9632 b'\\xe0\\xb8'2992 b'\\x86'135 '่'9645 'า'9632 b'\\xe0\\xb8'2992 b'\\x9f'160 'ั'9631 'น'9614 'จ'9605 'น'9614 'บ'9615 'ร'9622 'ร'9622 'ล'9623 'ั'9631 'ย'9621 '           '61274 b'\\xe0\\xb8'2992 b'\\xa4'165 b'\\xe0\\xb9'2993 b'\\x85'134 'ห'9628 'า'9632 'ใ'9642 'ค'9603 'ร'9622 'ค'9603 '้'9646 'ำ'9633 'ช'9606 'ู'9638 'ก'9601 'ู'9638 '้'9646 'บ'9615 'ร'9622 'ร'9622 'ล'9623 'ั'9631 'ง'9604 'ก'9601 '์'9647 ' '33 b'\\xe0\\xb8'2992 b'\\xaf'176 \n",
      "\n",
      "430 tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src2='''    ๏ แผ่นดินฮั่นเสื่อมโทรมแสนสังเวช  พระปกเกศกองบู๊กู้ขึ้นใหม่\n",
    "  สิบสองกษัตริย์ก่อนหน้าแลถัดไป       สององค์ไซร้โง่เขลาเบาปัญญา\n",
    "    ทรงนับถือขันทีเป็นที่พึ่ง           บ้านเมืองจึงวิปริตเป็นนักหนา\n",
    "  โฮจิ๋นเรียกทัพทั่วหัวเมืองมา         หมายจะฆ่ามดชั่วตัวสำคัญ\n",
    "    เหมือนขับไสไล่เสือจากเคหา      รับหมาป่าเข้ามาเลยอาสัญ\n",
    "  ฝ่ายอ้องอุ้นยุแยกให้แตกกัน          ใช้สาวนั้นเป็นชนวนชื่นชวนใจ\n",
    "    พลันลิฉุยกุยกีกลับก่อเหตุ          ช่างอาเพศจริงหนาฟ้าร้องไห้\n",
    "  ต้องรบราฆ่าฟันจนบรรลัย           ฤๅหาใครค้ำชูกู้บรรลังก์ ฯ'''\n",
    "print(src2)\n",
    "print(f'\\n{len(src2)} chars')\n",
    "tokens = TOKENIZER.encode(src2)\n",
    "assert TOKENIZER.decode(tokens) == src2\n",
    "print()\n",
    "TOKENIZER.printTokens(tokens)\n",
    "print(f'\\n{len(tokens)} tokens\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
