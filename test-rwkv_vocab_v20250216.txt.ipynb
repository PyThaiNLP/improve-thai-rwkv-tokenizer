{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce1e4bb-4169-451a-be07-1253941e7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################################################################\n",
      "\n",
      "This tokenizer is not used in any RWKV models yet. I plan to use it for the future multilang RWKV models.\n",
      "\n",
      "Benefits:\n",
      "\n",
      "* Good support of most languages, from European to CJK to Arabic and Hindi and more.\n",
      "\n",
      "* Clean vocab. Good for code too. Vocab size = 65536 (use 0 for <|endoftext|>).\n",
      "\n",
      "* Good at numbers: the numerical tokens are '0'~'9', '10'~'99', ' 0'~' 9', ' 10'~' 99'.\n",
      "\n",
      "* Very easy tokenization:\n",
      "\n",
      "** The input text must be in UTF-8.\n",
      "\n",
      "** Greedy encoding: always pick the longest (in bytes) token (with the highest id) that matches your UTF-8 bytes.\n",
      "\n",
      "* The tokenization result is surprisingly good, because the vocab respects word boundaries and UTF-8 boundaries.\n",
      "\n",
      "For 10x faster speed:\n",
      "mypyc rwkv_tokenizer.py\n",
      "python3 -c \"import rwkv_tokenizer\"\n",
      "\n",
      "#######################################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, random\n",
    "\n",
    "print('''\n",
    "#######################################################################################################################\n",
    "\n",
    "This tokenizer is not used in any RWKV models yet. I plan to use it for the future multilang RWKV models.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "* Good support of most languages, from European to CJK to Arabic and Hindi and more.\n",
    "\n",
    "* Clean vocab. Good for code too. Vocab size = 65536 (use 0 for <|endoftext|>).\n",
    "\n",
    "* Good at numbers: the numerical tokens are '0'~'9', '10'~'99', ' 0'~' 9', ' 10'~' 99'.\n",
    "\n",
    "* Very easy tokenization:\n",
    "\n",
    "** The input text must be in UTF-8.\n",
    "\n",
    "** Greedy encoding: always pick the longest (in bytes) token (with the highest id) that matches your UTF-8 bytes.\n",
    "\n",
    "* The tokenization result is surprisingly good, because the vocab respects word boundaries and UTF-8 boundaries.\n",
    "\n",
    "For 10x faster speed:\n",
    "mypyc rwkv_tokenizer.py\n",
    "python3 -c \"import rwkv_tokenizer\"\n",
    "\n",
    "#######################################################################################################################\n",
    "''')\n",
    "\n",
    "########################################################################################################\n",
    "# Tokenizer #1 (reference, naive, slow)\n",
    "########################################################################################################\n",
    "\n",
    "class RWKV_TOKENIZER():\n",
    "    table: list[list[list[bytes]]]\n",
    "    good: list[set[int]]\n",
    "    wlen: list[int]\n",
    "    def __init__(self, file_name):\n",
    "        self.idx2token = {}\n",
    "        sorted = [] # must be already sorted\n",
    "        lines = open(file_name, \"r\", encoding=\"utf-8\").readlines()\n",
    "        for l in lines:\n",
    "            idx = int(l[:l.index(' ')])\n",
    "            x = eval(l[l.index(' '):l.rindex(' ')])\n",
    "            x = x.encode(\"utf-8\") if isinstance(x, str) else x\n",
    "            assert isinstance(x, bytes)\n",
    "            assert len(x) == int(l[l.rindex(' '):])\n",
    "            sorted += [x]\n",
    "            self.idx2token[idx] = x\n",
    "\n",
    "        self.token2idx = {}\n",
    "        for k, v in self.idx2token.items():\n",
    "            self.token2idx[v] = int(k)\n",
    "\n",
    "        # precompute some tables for fast matching\n",
    "        self.table = [[[] for j in range(256)] for i in range(256)]\n",
    "        self.good = [set() for i in range(256)]\n",
    "        self.wlen = [0 for i in range(256)]\n",
    "\n",
    "        for i in reversed(range(len(sorted))): # reverse order - match longer tokens first\n",
    "            s = sorted[i]\n",
    "            if len(s) >= 2:\n",
    "                s0 = int(s[0])\n",
    "                s1 = int(s[1])\n",
    "                self.table[s0][s1] += [s]\n",
    "                self.wlen[s0] = max(self.wlen[s0], len(s))\n",
    "                self.good[s0].add(s1)\n",
    "\n",
    "    def encodeBytes(self, src: bytes) -> list[int]:\n",
    "        src_len: int = len(src)\n",
    "        tokens: list[int] = []\n",
    "        i: int = 0\n",
    "        while i < src_len:\n",
    "            s: bytes = src[i : i + 1]\n",
    "\n",
    "            if i < src_len - 1:\n",
    "                s1: int = int(src[i + 1])\n",
    "                s0: int = int(src[i])\n",
    "                if s1 in self.good[s0]:\n",
    "                    sss: bytes = src[i : i + self.wlen[s0]]\n",
    "                    try:\n",
    "                        s = next(filter(sss.startswith, self.table[s0][s1]))\n",
    "                    except:\n",
    "                        pass\n",
    "            tokens.append(self.token2idx[s])\n",
    "            i += len(s)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def decodeBytes(self, tokens):\n",
    "        return b''.join(map(lambda i: self.idx2token[i], tokens))\n",
    "\n",
    "    def encode(self, src: str):\n",
    "        return self.encodeBytes(src.encode(\"utf-8\"))\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return self.decodeBytes(tokens).decode('utf-8')\n",
    "\n",
    "    def printTokens(self, tokens):\n",
    "        for i in tokens:\n",
    "            s = self.idx2token[i]\n",
    "            try:\n",
    "                s = s.decode('utf-8')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'{repr(s)}{i}', end=' ')\n",
    "            # print(repr(s), i)\n",
    "        print()\n",
    "\n",
    "########################################################################################################\n",
    "# Tokenizer #2 (trie, faster) https://github.com/TkskKurumi/ChatRWKV-TRIE-Tokenizer\n",
    "########################################################################################################\n",
    "\n",
    "class TRIE:\n",
    "    __slots__ = tuple(\"ch,to,values,front\".split(\",\"))\n",
    "    to:list\n",
    "    values:set\n",
    "    def __init__(self, front=None, ch=None):\n",
    "        self.ch = ch\n",
    "        self.to = [None for ch in range(256)]\n",
    "        self.values = set()\n",
    "        self.front = front\n",
    "\n",
    "    def __repr__(self):\n",
    "        fr = self\n",
    "        ret = []\n",
    "        while(fr!=None):\n",
    "            if(fr.ch!=None):\n",
    "                ret.append(fr.ch)\n",
    "            fr = fr.front\n",
    "        return \"<TRIE %s %s>\"%(ret[::-1], self.values)\n",
    "    \n",
    "    def add(self, key:bytes, idx:int=0, val=None):\n",
    "        if(idx == len(key)):\n",
    "            if(val is None):\n",
    "                val = key\n",
    "            self.values.add(val)\n",
    "            return self\n",
    "        ch = key[idx]\n",
    "        if(self.to[ch] is None):\n",
    "            self.to[ch] = TRIE(front=self, ch=ch)\n",
    "        return self.to[ch].add(key, idx=idx+1, val=val)\n",
    "    \n",
    "    def find_longest(self, key:bytes, idx:int=0):\n",
    "        u:TRIE = self\n",
    "        ch:int = key[idx]\n",
    "        \n",
    "        while(u.to[ch] is not None):\n",
    "            u = u.to[ch]\n",
    "            idx += 1\n",
    "            if(u.values):\n",
    "                ret = idx, u, u.values\n",
    "            if(idx==len(key)):\n",
    "                break\n",
    "            ch = key[idx]\n",
    "        return ret\n",
    "\n",
    "class TRIE_TOKENIZER():\n",
    "    def __init__(self, file_name):\n",
    "        self.idx2token = {}\n",
    "        sorted = [] # must be already sorted\n",
    "        with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "        for l in lines:\n",
    "            idx = int(l[:l.index(' ')])\n",
    "            x = eval(l[l.index(' '):l.rindex(' ')])\n",
    "            x = x.encode(\"utf-8\") if isinstance(x, str) else x\n",
    "            assert isinstance(x, bytes)\n",
    "            assert len(x) == int(l[l.rindex(' '):])\n",
    "            sorted += [x]\n",
    "            self.idx2token[idx] = x\n",
    "\n",
    "        self.token2idx = {}\n",
    "        for k,v in self.idx2token.items():\n",
    "            self.token2idx[v] = int(k)\n",
    "\n",
    "        self.root = TRIE()\n",
    "        for t, i in self.token2idx.items():\n",
    "            _ = self.root.add(t, val=(t, i))\n",
    "\n",
    "    def encodeBytes(self, src:bytes):\n",
    "        idx:int = 0\n",
    "        tokens = []\n",
    "        while (idx < len(src)):\n",
    "            _idx:int = idx\n",
    "            idx, _, values = self.root.find_longest(src, idx)\n",
    "            assert(idx != _idx)\n",
    "            _, token = next(iter(values))            \n",
    "            tokens.append(token)\n",
    "        return tokens\n",
    "\n",
    "    def decodeBytes(self, tokens):\n",
    "        return b''.join(map(lambda i: self.idx2token[i], tokens))\n",
    "\n",
    "    def encode(self, src):\n",
    "        return self.encodeBytes(src.encode(\"utf-8\"))\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return self.decodeBytes(tokens).decode('utf-8')\n",
    "\n",
    "    def printTokens(self, tokens):\n",
    "        for i in tokens:\n",
    "            s = self.idx2token[i]\n",
    "            try:\n",
    "                s = s.decode('utf-8')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'{repr(s)}{i}', end=' ')\n",
    "        print()\n",
    "\n",
    "########################################################################################################\n",
    "# Demo\n",
    "########################################################################################################\n",
    "\n",
    "TOKENIZER = RWKV_TOKENIZER('rwkv_vocab_v20250216.txt')\n",
    "TRIE_TEST = TRIE_TOKENIZER('rwkv_vocab_v20250216.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7596e9f-5b75-407e-bd8d-0b23ce6d3017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ภาษาไทย หรือ ภาษาไทยกลาง เป็นภาษาในกลุ่มภาษาไท สาขาย่อยเชียงแสน ซึ่งเป็นกลุ่มย่อยของตระกูลภาษาขร้า-ไท และเป็นภาษาราชการ และภาษาประจำชาติของประเทศไทย[3][4] มีการสันนิษฐานว่าภาษาในตระกูลนี้มีถิ่นกำเนิดจากทางตอนใต้ของประเทศจีน และนักภาษาศาสตร์บางส่วนเสนอว่า ภาษาไทยน่าจะมีความเชื่อมโยงกับตระกูลภาษาออสโตร-เอเชียติก ตระกูลภาษาออสโตรนีเซียน และตระกูลภาษาจีน-ทิเบต\n",
      "ภาษาไทยเป็นภาษาที่มีระดับเสียงของคำแน่นอนหรือวรรณยุกต์เช่นเดียวกับภาษาจีน และออกเสียงแยกคำต่อคำ\n",
      "ภาษาไทยปรากฏครั้งแรกในพุทธศักราช 1826 โดยพ่อขุนรามคำแหง และปรากฏอย่างสากลและใช้ในงานของราชการ เมื่อวันที่ 31 มีนาคม พุทธศักราช 2476 ด้วยการก่อตั้งสำนักงานราชบัณฑิตยสภาขึ้น และปฏิรูปภาษาไทย พุทธศักราช 2485\n",
      "\n",
      "659 chars\n",
      "\n",
      "'ภาษา'65381 'ไทย'59752 ' หรือ'66366 ' '33 'ภาษา'65381 'ไทย'59752 'กลาง'65619 ' เป็น'66367 'ภาษา'65381 'ใน'44172 'กลุ่ม'67034 'ภาษา'65381 'ไท'44188 ' ส'28408 'า'9632 'ขาย'59439 '่อย'59301 'เชียง'66974 'แสน'59726 ' ซึ่งเป็น'67877 'กลุ่ม'67034 'ย่'44290 'อย'44030 'ของ'59366 'ตร'44159 'ะ'9630 'ก'9601 'ูล'44082 'ภาษา'65381 'ข'9602 'ร'9622 '้า'43340 '-'46 'ไท'44188 ' และ'62396 'เป็น'65571 'ภาษา'65381 'ราชการ'67407 ' และ'62396 'ภาษา'65381 'ประจำ'67071 'ชาติ'65482 'ของ'59366 'ประเทศไทย'67920 '['92 '3'52 ']['1695 '4'53 ']'94 ' มี'50425 'การ'59026 'สัน'59640 'นิ'44302 'ษ'9626 'ฐาน'59585 'ว่า'59400 'ภาษา'65381 'ใน'44172 'ตร'44159 'ะ'9630 'ก'9601 'ูล'44082 'นี้'59735 'มี'44303 'ถ'9611 'ิ่น'59445 'กำ'44399 'เน'44336 'ิด'44101 'จาก'59353 'ทาง'59453 'ตอน'59468 'ใต้'59601 'ของ'59366 'ประเทศ'67289 'จีน'59557 ' และ'62396 'นัก'59658 'ภาษา'65381 'ศาสตร์'67268 'บาง'59164 'ส่วน'65517 'เสนอ'65723 'ว่า'59400 ' '33 'ภาษา'65381 'ไทย'59752 'น่าจะ'67040 'มีความ'67352 'เชื่อม'67298 'โย'44027 'ง'9604 'กับ'59709 'ตร'44159 'ะ'9630 'ก'9601 'ูล'44082 'ภาษา'65381 'ออ'44234 'ส'9627 'โต'44206 'ร'9622 '-'46 'เอเชีย'67307 'ติ'44107 'ก'9601 ' '33 'ตร'44159 'ะ'9630 'ก'9601 'ูล'44082 'ภาษา'65381 'ออ'44234 'ส'9627 'โต'44206 'ร'9622 'นี'44132 'เซีย'65346 'น'9614 ' และ'62396 'ตร'44159 'ะ'9630 'ก'9601 'ูล'44082 'ภาษา'65381 'จีน'59557 '-'46 'ทิ'44317 'เบ'44122 'ต'9610 '\\n'11 'ภาษา'65381 'ไทย'59752 'เป็น'65571 'ภาษา'65381 'ที่มี'67065 'ระดับ'66855 'เสียง'67135 'ของ'59366 'คำ'44370 'แน่นอน'67413 'หรือ'65368 'วรรณ'65595 'ยุ'44150 'ก'9601 'ต์'44074 'เช่น'65515 'เดียว'67067 'กับ'59709 'ภาษา'65381 'จีน'59557 ' และ'62396 'ออก'59318 'เสียง'67135 'แยก'59504 'คำ'44370 'ต่อ'59597 'คำ'44370 '\\n'11 'ภาษา'65381 'ไทย'59752 'ปรากฏ'66949 'ครั้งแรก'67772 'ใน'44172 'พุทธ'65648 'ศัก'59546 'ราช'59382 ' 18'3491 '26'646 ' โดย'62409 'พ่อ'59274 'ข'9602 'ุ'9637 'น'9614 'ราม'59592 'คำ'44370 'แห'44043 'ง'9604 ' และ'62396 'ปรากฏ'66949 'อย่าง'66864 'สา'44108 'กล'44392 'และ'59241 'ใช้'59559 'ใน'44172 'งาน'59237 'ของ'59366 'ราชการ'67407 ' เมื่อ'67201 'วันที่'67448 ' 31'3504 ' มีนาคม'67560 ' พ'28413 'ุ'9637 'ทธ'44323 'ศัก'59546 'ราช'59382 ' 24'3497 '76'696 ' '33 'ด้วยการ'67590 'ก่อ'59611 'ตั้ง'65594 'สำนักงาน'67841 'ราช'59382 'บั'44389 'ณ'9608 'ฑ'19293 'ิต'44129 'ย'9621 'สภา'59322 'ขึ้น'65306 ' และ'62396 'ปฏิ'59632 'รูป'59260 'ภาษา'65381 'ไทย'59752 ' พ'28413 'ุ'9637 'ทธ'44323 'ศัก'59546 'ราช'59382 ' 24'3497 '85'705 \n",
      "\n",
      "225 tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src1 = '''ภาษาไทย หรือ ภาษาไทยกลาง เป็นภาษาในกลุ่มภาษาไท สาขาย่อยเชียงแสน ซึ่งเป็นกลุ่มย่อยของตระกูลภาษาขร้า-ไท และเป็นภาษาราชการ และภาษาประจำชาติของประเทศไทย[3][4] มีการสันนิษฐานว่าภาษาในตระกูลนี้มีถิ่นกำเนิดจากทางตอนใต้ของประเทศจีน และนักภาษาศาสตร์บางส่วนเสนอว่า ภาษาไทยน่าจะมีความเชื่อมโยงกับตระกูลภาษาออสโตร-เอเชียติก ตระกูลภาษาออสโตรนีเซียน และตระกูลภาษาจีน-ทิเบต\n",
    "ภาษาไทยเป็นภาษาที่มีระดับเสียงของคำแน่นอนหรือวรรณยุกต์เช่นเดียวกับภาษาจีน และออกเสียงแยกคำต่อคำ\n",
    "ภาษาไทยปรากฏครั้งแรกในพุทธศักราช 1826 โดยพ่อขุนรามคำแหง และปรากฏอย่างสากลและใช้ในงานของราชการ เมื่อวันที่ 31 มีนาคม พุทธศักราช 2476 ด้วยการก่อตั้งสำนักงานราชบัณฑิตยสภาขึ้น และปฏิรูปภาษาไทย พุทธศักราช 2485'''\n",
    "\n",
    "print(src1)\n",
    "print(f'\\n{len(src1)} chars')\n",
    "tokens = TOKENIZER.encode(src1)\n",
    "assert TOKENIZER.decode(tokens) == src1\n",
    "print()\n",
    "TOKENIZER.printTokens(tokens)\n",
    "print(f'\\n{len(tokens)} tokens\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcde151c-f184-45ae-bb04-9470c9a81489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ๏ แผ่นดินฮั่นเสื่อมโทรมแสนสังเวช  พระปกเกศกองบู๊กู้ขึ้นใหม่\n",
      "  สิบสองกษัตริย์ก่อนหน้าแลถัดไป       สององค์ไซร้โง่เขลาเบาปัญญา\n",
      "    ทรงนับถือขันทีเป็นที่พึ่ง           บ้านเมืองจึงวิปริตเป็นนักหนา\n",
      "  โฮจิ๋นเรียกทัพทั่วหัวเมืองมา         หมายจะฆ่ามดชั่วตัวสำคัญ\n",
      "    เหมือนขับไสไล่เสือจากเคหา      รับหมาป่าเข้ามาเลยอาสัญ\n",
      "  ฝ่ายอ้องอุ้นยุแยกให้แตกกัน          ใช้สาวนั้นเป็นชนวนชื่นชวนใจ\n",
      "    พลันลิฉุยกุยกีกลับก่อเหตุ          ช่างอาเพศจริงหนาฟ้าร้องไห้\n",
      "  ต้องรบราฆ่าฟันจนบรรลัย           ฤๅหาใครค้ำชูกู้บรรลังก์ ฯ\n",
      "\n",
      "512 chars\n",
      "\n",
      "'    '19314 '๏'19277 ' '33 'แผ่น'65549 'ดิน'59528 'ฮ'19284 'ั'9631 '่น'44272 'เส'44277 'ื่อ'59431 'ม'9620 'โทร'59492 'ม'9620 'แสน'59726 'สัง'59680 'เว'44380 'ช'9606 '  '267 'พระ'59426 'ปก'44178 'เก'44076 'ศ'9625 'กอง'59577 'บู'44059 '๊'19253 'ก'9601 'ู้'44243 'ขึ้น'65306 'ใหม่'65641 '\\n  '3331 'สิ'44056 'บ'9615 'สอง'59676 'ก'9601 'ษ'9626 'ั'9631 'ตร'44159 'ิ'9634 'ย์'44202 'ก่อนหน้า'67867 'แล'44328 'ถ'9611 'ัด'44186 'ไป'44326 '       '44412 'สอง'59676 'องค์'65561 'ไซ'44379 'ร'9622 '้'9646 'โ'9641 'ง'9604 '่'9645 'เข'44102 'ลา'44228 'เบา'59564 'ปัญญา'66884 '\\n    '28423 'ทรง'59376 'นับ'59309 'ถือ'59473 'ขั'44065 'น'9614 'ที'44237 'เป็นที่'67651 'พ'9618 'ึ่ง'59384 '           '62422 'บ้าน'65535 'เมือง'66957 'จึง'59675 'วิ'44034 'ปริ'59435 'ต'9610 'เป็น'65571 'นัก'59658 'หน'44036 'า'9632 '\\n  '3331 'โฮ'44025 'จิ'44183 '๋'19278 'น'9614 'เรียก'67105 'ทัพ'59277 'ทั่ว'65502 'หัว'59452 'เมือง'66957 'มา'44184 '         '55323 'หมาย'65330 'จะ'44339 'ฆ่า'59470 'ม'9620 'ด'9609 'ชั่ว'65728 'ตัว'59550 'สำคัญ'67073 '\\n    '28423 'เหมือน'67274 'ขับ'59319 'ไ'9643 'ส'9627 'ไล่'59647 'เส'44277 'ือ'44227 'จาก'59353 'เค'44318 'หา'44176 '      '36287 'รับ'59609 'หม'44180 'า'9632 'ป่า'59555 'เข้ามา'67278 'เลย'59474 'อา'44294 'สัญ'59734 '\\n  '3331 'ฝ่าย'65705 'อ'9629 '้อง'59471 'อุ'43974 '้น'44028 'ยุ'44150 'แยก'59504 'ให้'59280 'แตก'59278 'กัน'59653 '          '59776 'ใช้'59559 'สาว'59541 'นั้น'65653 'เป็น'65571 'ชน'44327 'วน'44141 'ช'9606 'ื่'43338 'น'9614 'ชวน'59224 'ใจ'44019 '\\n    '28423 'พล'44004 'ัน'44152 'ลิ'44018 'ฉ'19295 'ุ'9637 'ยก'44296 'ุ'9637 'ยก'44296 'ี'9635 'กลับ'65654 'ก่อ'59611 'เหตุ'65435 '          '59776 'ช่าง'65382 'อา'44294 'เพศ'59284 'จริง'65565 'หน'44036 'า'9632 'ฟ้า'59215 'ร้อง'65726 'ไ'9643 'ห'9628 '้'9646 '\\n  '3331 'ต้อง'65597 'ร'9622 'บร'44075 'า'9632 'ฆ่า'59470 'ฟัน'59425 'จน'44012 'บรร'59641 'ล'9623 'ัย'44268 '           '62422 'ฤ'19282 'ๅ'19289 'หา'44176 'ใคร'59476 'ค'9603 '้ำ'44168 'ชู'44250 'ก'9601 'ู้'44243 'บรร'59641 'ลัง'59207 'ก'9601 '์'9647 ' '33 'ฯ'19285 \n",
      "\n",
      "193 tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src2='''    ๏ แผ่นดินฮั่นเสื่อมโทรมแสนสังเวช  พระปกเกศกองบู๊กู้ขึ้นใหม่\n",
    "  สิบสองกษัตริย์ก่อนหน้าแลถัดไป       สององค์ไซร้โง่เขลาเบาปัญญา\n",
    "    ทรงนับถือขันทีเป็นที่พึ่ง           บ้านเมืองจึงวิปริตเป็นนักหนา\n",
    "  โฮจิ๋นเรียกทัพทั่วหัวเมืองมา         หมายจะฆ่ามดชั่วตัวสำคัญ\n",
    "    เหมือนขับไสไล่เสือจากเคหา      รับหมาป่าเข้ามาเลยอาสัญ\n",
    "  ฝ่ายอ้องอุ้นยุแยกให้แตกกัน          ใช้สาวนั้นเป็นชนวนชื่นชวนใจ\n",
    "    พลันลิฉุยกุยกีกลับก่อเหตุ          ช่างอาเพศจริงหนาฟ้าร้องไห้\n",
    "  ต้องรบราฆ่าฟันจนบรรลัย           ฤๅหาใครค้ำชูกู้บรรลังก์ ฯ'''\n",
    "print(src2)\n",
    "print(f'\\n{len(src2)} chars')\n",
    "tokens = TOKENIZER.encode(src2)\n",
    "assert TOKENIZER.decode(tokens) == src2\n",
    "print()\n",
    "TOKENIZER.printTokens(tokens)\n",
    "print(f'\\n{len(tokens)} tokens\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
