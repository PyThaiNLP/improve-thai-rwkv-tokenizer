{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce1e4bb-4169-451a-be07-1253941e7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################################################################\n",
      "\n",
      "This tokenizer is not used in any RWKV models yet. I plan to use it for the future multilang RWKV models.\n",
      "\n",
      "Benefits:\n",
      "\n",
      "* Good support of most languages, from European to CJK to Arabic and Hindi and more.\n",
      "\n",
      "* Clean vocab. Good for code too. Vocab size = 65536 (use 0 for <|endoftext|>).\n",
      "\n",
      "* Good at numbers: the numerical tokens are '0'~'9', '10'~'99', ' 0'~' 9', ' 10'~' 99'.\n",
      "\n",
      "* Very easy tokenization:\n",
      "\n",
      "** The input text must be in UTF-8.\n",
      "\n",
      "** Greedy encoding: always pick the longest (in bytes) token (with the highest id) that matches your UTF-8 bytes.\n",
      "\n",
      "* The tokenization result is surprisingly good, because the vocab respects word boundaries and UTF-8 boundaries.\n",
      "\n",
      "For 10x faster speed:\n",
      "mypyc rwkv_tokenizer.py\n",
      "python3 -c \"import rwkv_tokenizer\"\n",
      "\n",
      "#######################################################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time, random\n",
    "\n",
    "print('''\n",
    "#######################################################################################################################\n",
    "\n",
    "This tokenizer is not used in any RWKV models yet. I plan to use it for the future multilang RWKV models.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "* Good support of most languages, from European to CJK to Arabic and Hindi and more.\n",
    "\n",
    "* Clean vocab. Good for code too. Vocab size = 65536 (use 0 for <|endoftext|>).\n",
    "\n",
    "* Good at numbers: the numerical tokens are '0'~'9', '10'~'99', ' 0'~' 9', ' 10'~' 99'.\n",
    "\n",
    "* Very easy tokenization:\n",
    "\n",
    "** The input text must be in UTF-8.\n",
    "\n",
    "** Greedy encoding: always pick the longest (in bytes) token (with the highest id) that matches your UTF-8 bytes.\n",
    "\n",
    "* The tokenization result is surprisingly good, because the vocab respects word boundaries and UTF-8 boundaries.\n",
    "\n",
    "For 10x faster speed:\n",
    "mypyc rwkv_tokenizer.py\n",
    "python3 -c \"import rwkv_tokenizer\"\n",
    "\n",
    "#######################################################################################################################\n",
    "''')\n",
    "\n",
    "########################################################################################################\n",
    "# Tokenizer #1 (reference, naive, slow)\n",
    "########################################################################################################\n",
    "\n",
    "class RWKV_TOKENIZER():\n",
    "    table: list[list[list[bytes]]]\n",
    "    good: list[set[int]]\n",
    "    wlen: list[int]\n",
    "    def __init__(self, file_name):\n",
    "        self.idx2token = {}\n",
    "        sorted = [] # must be already sorted\n",
    "        lines = open(file_name, \"r\", encoding=\"utf-8\").readlines()\n",
    "        for l in lines:\n",
    "            idx = int(l[:l.index(' ')])\n",
    "            x = eval(l[l.index(' '):l.rindex(' ')])\n",
    "            x = x.encode(\"utf-8\") if isinstance(x, str) else x\n",
    "            assert isinstance(x, bytes)\n",
    "            assert len(x) == int(l[l.rindex(' '):])\n",
    "            sorted += [x]\n",
    "            self.idx2token[idx] = x\n",
    "\n",
    "        self.token2idx = {}\n",
    "        for k, v in self.idx2token.items():\n",
    "            self.token2idx[v] = int(k)\n",
    "\n",
    "        # precompute some tables for fast matching\n",
    "        self.table = [[[] for j in range(256)] for i in range(256)]\n",
    "        self.good = [set() for i in range(256)]\n",
    "        self.wlen = [0 for i in range(256)]\n",
    "\n",
    "        for i in reversed(range(len(sorted))): # reverse order - match longer tokens first\n",
    "            s = sorted[i]\n",
    "            if len(s) >= 2:\n",
    "                s0 = int(s[0])\n",
    "                s1 = int(s[1])\n",
    "                self.table[s0][s1] += [s]\n",
    "                self.wlen[s0] = max(self.wlen[s0], len(s))\n",
    "                self.good[s0].add(s1)\n",
    "\n",
    "    def encodeBytes(self, src: bytes) -> list[int]:\n",
    "        src_len: int = len(src)\n",
    "        tokens: list[int] = []\n",
    "        i: int = 0\n",
    "        while i < src_len:\n",
    "            s: bytes = src[i : i + 1]\n",
    "\n",
    "            if i < src_len - 1:\n",
    "                s1: int = int(src[i + 1])\n",
    "                s0: int = int(src[i])\n",
    "                if s1 in self.good[s0]:\n",
    "                    sss: bytes = src[i : i + self.wlen[s0]]\n",
    "                    try:\n",
    "                        s = next(filter(sss.startswith, self.table[s0][s1]))\n",
    "                    except:\n",
    "                        pass\n",
    "            tokens.append(self.token2idx[s])\n",
    "            i += len(s)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def decodeBytes(self, tokens):\n",
    "        return b''.join(map(lambda i: self.idx2token[i], tokens))\n",
    "\n",
    "    def encode(self, src: str):\n",
    "        return self.encodeBytes(src.encode(\"utf-8\"))\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return self.decodeBytes(tokens).decode('utf-8')\n",
    "\n",
    "    def printTokens(self, tokens):\n",
    "        for i in tokens:\n",
    "            s = self.idx2token[i]\n",
    "            try:\n",
    "                s = s.decode('utf-8')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'{repr(s)}{i}', end=' ')\n",
    "            # print(repr(s), i)\n",
    "        print()\n",
    "\n",
    "########################################################################################################\n",
    "# Tokenizer #2 (trie, faster) https://github.com/TkskKurumi/ChatRWKV-TRIE-Tokenizer\n",
    "########################################################################################################\n",
    "\n",
    "class TRIE:\n",
    "    __slots__ = tuple(\"ch,to,values,front\".split(\",\"))\n",
    "    to:list\n",
    "    values:set\n",
    "    def __init__(self, front=None, ch=None):\n",
    "        self.ch = ch\n",
    "        self.to = [None for ch in range(256)]\n",
    "        self.values = set()\n",
    "        self.front = front\n",
    "\n",
    "    def __repr__(self):\n",
    "        fr = self\n",
    "        ret = []\n",
    "        while(fr!=None):\n",
    "            if(fr.ch!=None):\n",
    "                ret.append(fr.ch)\n",
    "            fr = fr.front\n",
    "        return \"<TRIE %s %s>\"%(ret[::-1], self.values)\n",
    "    \n",
    "    def add(self, key:bytes, idx:int=0, val=None):\n",
    "        if(idx == len(key)):\n",
    "            if(val is None):\n",
    "                val = key\n",
    "            self.values.add(val)\n",
    "            return self\n",
    "        ch = key[idx]\n",
    "        if(self.to[ch] is None):\n",
    "            self.to[ch] = TRIE(front=self, ch=ch)\n",
    "        return self.to[ch].add(key, idx=idx+1, val=val)\n",
    "    \n",
    "    def find_longest(self, key:bytes, idx:int=0):\n",
    "        u:TRIE = self\n",
    "        ch:int = key[idx]\n",
    "        \n",
    "        while(u.to[ch] is not None):\n",
    "            u = u.to[ch]\n",
    "            idx += 1\n",
    "            if(u.values):\n",
    "                ret = idx, u, u.values\n",
    "            if(idx==len(key)):\n",
    "                break\n",
    "            ch = key[idx]\n",
    "        return ret\n",
    "\n",
    "class TRIE_TOKENIZER():\n",
    "    def __init__(self, file_name):\n",
    "        self.idx2token = {}\n",
    "        sorted = [] # must be already sorted\n",
    "        with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "        for l in lines:\n",
    "            idx = int(l[:l.index(' ')])\n",
    "            x = eval(l[l.index(' '):l.rindex(' ')])\n",
    "            x = x.encode(\"utf-8\") if isinstance(x, str) else x\n",
    "            assert isinstance(x, bytes)\n",
    "            assert len(x) == int(l[l.rindex(' '):])\n",
    "            sorted += [x]\n",
    "            self.idx2token[idx] = x\n",
    "\n",
    "        self.token2idx = {}\n",
    "        for k,v in self.idx2token.items():\n",
    "            self.token2idx[v] = int(k)\n",
    "\n",
    "        self.root = TRIE()\n",
    "        for t, i in self.token2idx.items():\n",
    "            _ = self.root.add(t, val=(t, i))\n",
    "\n",
    "    def encodeBytes(self, src:bytes):\n",
    "        idx:int = 0\n",
    "        tokens = []\n",
    "        while (idx < len(src)):\n",
    "            _idx:int = idx\n",
    "            idx, _, values = self.root.find_longest(src, idx)\n",
    "            assert(idx != _idx)\n",
    "            _, token = next(iter(values))            \n",
    "            tokens.append(token)\n",
    "        return tokens\n",
    "\n",
    "    def decodeBytes(self, tokens):\n",
    "        return b''.join(map(lambda i: self.idx2token[i], tokens))\n",
    "\n",
    "    def encode(self, src):\n",
    "        return self.encodeBytes(src.encode(\"utf-8\"))\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return self.decodeBytes(tokens).decode('utf-8')\n",
    "\n",
    "    def printTokens(self, tokens):\n",
    "        for i in tokens:\n",
    "            s = self.idx2token[i]\n",
    "            try:\n",
    "                s = s.decode('utf-8')\n",
    "            except:\n",
    "                pass\n",
    "            print(f'{repr(s)}{i}', end=' ')\n",
    "        print()\n",
    "\n",
    "########################################################################################################\n",
    "# Demo\n",
    "########################################################################################################\n",
    "\n",
    "TOKENIZER = RWKV_TOKENIZER('rwkv_vocab_v20250216.txt')\n",
    "TRIE_TEST = TRIE_TOKENIZER('rwkv_vocab_v20250216.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7596e9f-5b75-407e-bd8d-0b23ce6d3017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ภาษาไทย หรือ ภาษาไทยกลาง เป็นภาษาในกลุ่มภาษาไท สาขาย่อยเชียงแสน ซึ่งเป็นกลุ่มย่อยของตระกูลภาษาขร้า-ไท และเป็นภาษาราชการ และภาษาประจำชาติของประเทศไทย[3][4] มีการสันนิษฐานว่าภาษาในตระกูลนี้มีถิ่นกำเนิดจากทางตอนใต้ของประเทศจีน และนักภาษาศาสตร์บางส่วนเสนอว่า ภาษาไทยน่าจะมีความเชื่อมโยงกับตระกูลภาษาออสโตร-เอเชียติก ตระกูลภาษาออสโตรนีเซียน และตระกูลภาษาจีน-ทิเบต\n",
      "ภาษาไทยเป็นภาษาที่มีระดับเสียงของคำแน่นอนหรือวรรณยุกต์เช่นเดียวกับภาษาจีน และออกเสียงแยกคำต่อคำ\n",
      "ภาษาไทยปรากฏครั้งแรกในพุทธศักราช 1826 โดยพ่อขุนรามคำแหง และปรากฏอย่างสากลและใช้ในงานของราชการ เมื่อวันที่ 31 มีนาคม พุทธศักราช 2476 ด้วยการก่อตั้งสำนักงานราชบัณฑิตยสภาขึ้น และปฏิรูปภาษาไทย พุทธศักราช 2485\n",
      "\n",
      "659 chars\n",
      "\n",
      "'ภาษา'65660 'ไทย'59678 ' หรือ'66364 ' '32 'ภาษา'65660 'ไทย'59678 'กลาง'65639 ' เป็น'66366 'ภาษา'65660 'ใน'44175 'กลุ่ม'66880 'ภาษา'65660 'ไท'44060 ' ส'28409 'า'9631 'ขาย'59465 '่อย'59234 'เชียง'67061 'แสน'59506 ' ซึ่งเป็น'67876 'กลุ่ม'66880 'ย่'44267 'อย'44327 'ของ'59639 'ตร'44233 'ะ'9629 'ก'9600 'ูล'44155 'ภาษา'65660 'ข'9601 'ร'9621 '้า'43339 '-'45 'ไท'44060 ' และ'62404 'เป็น'65412 'ภาษา'65660 'ราชการ'67386 ' และ'62404 'ภาษา'65660 'ประจำ'67079 'ชาติ'65669 'ของ'59639 'ประเทศไทย'67891 '['91 '3'51 ']['1694 '4'52 ']'93 ' มี'50428 'การ'59025 'สัน'59495 'นิ'43993 'ษ'9625 'ฐาน'59694 'ว่า'59497 'ภาษา'65660 'ใน'44175 'ตร'44233 'ะ'9629 'ก'9600 'ูล'44155 'นี้'59293 'มี'44262 'ถ'9610 'ิ่น'59376 'กำ'44099 'เน'44010 'ิด'44103 'จาก'59606 'ทาง'59243 'ตอน'59553 'ใต้'59683 'ของ'59639 'ประเทศ'67446 'จีน'59414 ' และ'62404 'นัก'59295 'ภาษา'65660 'ศาสตร์'67322 'บาง'59600 'ส่วน'65536 'เสนอ'65703 'ว่า'59497 ' '32 'ภาษา'65660 'ไทย'59678 'น่าจะ'66950 'มีความ'67296 'เชื่อม'67364 'โย'44087 'ง'9603 'กับ'59538 'ตร'44233 'ะ'9629 'ก'9600 'ูล'44155 'ภาษา'65660 'ออ'44351 'ส'9626 'โต'43988 'ร'9621 '-'45 'เอเชีย'67279 'ติ'44365 'ก'9600 ' '32 'ตร'44233 'ะ'9629 'ก'9600 'ูล'44155 'ภาษา'65660 'ออ'44351 'ส'9626 'โต'43988 'ร'9621 'นี'44253 'เซีย'65714 'น'9613 ' และ'62404 'ตร'44233 'ะ'9629 'ก'9600 'ูล'44155 'ภาษา'65660 'จีน'59414 '-'45 'ทิ'44399 'เบ'44220 'ต'9609 '\\n'10 'ภาษา'65660 'ไทย'59678 'เป็น'65412 'ภาษา'65660 'ที่มี'66915 'ระดับ'66869 'เสียง'66942 'ของ'59639 'คำ'44191 'แน่นอน'67424 'หรือ'65532 'วรรณ'65705 'ยุ'44110 'ก'9600 'ต์'44009 'เช่น'65662 'เดียว'67107 'กับ'59538 'ภาษา'65660 'จีน'59414 ' และ'62404 'ออก'59660 'เสียง'66942 'แยก'59624 'คำ'44191 'ต่อ'59757 'คำ'44191 '\\n'10 'ภาษา'65660 'ไทย'59678 'ปรากฏ'66962 'ครั้งแรก'67797 'ใน'44175 'พุทธ'65686 'ศัก'59246 'ราช'59470 ' 18'3490 '26'645 ' โดย'62407 'พ่อ'59605 'ข'9601 'ุ'9636 'น'9613 'ราม'59331 'คำ'44191 'แห'44197 'ง'9603 ' และ'62404 'ปรากฏ'66962 'อย่าง'67032 'สา'44303 'กล'44187 'และ'59676 'ใช้'59561 'ใน'44175 'งาน'59736 'ของ'59639 'ราชการ'67386 ' เมื่อ'67203 'วันที่'67473 ' 31'3503 ' มีนาคม'67555 ' พ'28410 'ุ'9636 'ทธ'44179 'ศัก'59246 'ราช'59470 ' 24'3496 '76'695 ' '32 'ด้วยการ'67678 'ก่อ'59167 'ตั้ง'65426 'สำนักงาน'67824 'ราช'59470 'บั'44022 'ณ'9607 'ฑ'19287 'ิต'44346 'ย'9620 'สภา'59268 'ขึ้น'65482 ' และ'62404 'ปฏิ'59760 'รูป'59744 'ภาษา'65660 'ไทย'59678 ' พ'28410 'ุ'9636 'ทธ'44179 'ศัก'59246 'ราช'59470 ' 24'3496 '85'704 \n",
      "\n",
      "225 tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src1 = '''ภาษาไทย หรือ ภาษาไทยกลาง เป็นภาษาในกลุ่มภาษาไท สาขาย่อยเชียงแสน ซึ่งเป็นกลุ่มย่อยของตระกูลภาษาขร้า-ไท และเป็นภาษาราชการ และภาษาประจำชาติของประเทศไทย[3][4] มีการสันนิษฐานว่าภาษาในตระกูลนี้มีถิ่นกำเนิดจากทางตอนใต้ของประเทศจีน และนักภาษาศาสตร์บางส่วนเสนอว่า ภาษาไทยน่าจะมีความเชื่อมโยงกับตระกูลภาษาออสโตร-เอเชียติก ตระกูลภาษาออสโตรนีเซียน และตระกูลภาษาจีน-ทิเบต\n",
    "ภาษาไทยเป็นภาษาที่มีระดับเสียงของคำแน่นอนหรือวรรณยุกต์เช่นเดียวกับภาษาจีน และออกเสียงแยกคำต่อคำ\n",
    "ภาษาไทยปรากฏครั้งแรกในพุทธศักราช 1826 โดยพ่อขุนรามคำแหง และปรากฏอย่างสากลและใช้ในงานของราชการ เมื่อวันที่ 31 มีนาคม พุทธศักราช 2476 ด้วยการก่อตั้งสำนักงานราชบัณฑิตยสภาขึ้น และปฏิรูปภาษาไทย พุทธศักราช 2485'''\n",
    "\n",
    "print(src1)\n",
    "print(f'\\n{len(src1)} chars')\n",
    "tokens = TOKENIZER.encode(src1)\n",
    "assert TOKENIZER.decode(tokens) == src1\n",
    "print()\n",
    "TOKENIZER.printTokens(tokens)\n",
    "print(f'\\n{len(tokens)} tokens\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcde151c-f184-45ae-bb04-9470c9a81489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ๏ แผ่นดินฮั่นเสื่อมโทรมแสนสังเวช  พระปกเกศกองบู๊กู้ขึ้นใหม่\n",
      "  สิบสองกษัตริย์ก่อนหน้าแลถัดไป       สององค์ไซร้โง่เขลาเบาปัญญา\n",
      "    ทรงนับถือขันทีเป็นที่พึ่ง           บ้านเมืองจึงวิปริตเป็นนักหนา\n",
      "  โฮจิ๋นเรียกทัพทั่วหัวเมืองมา         หมายจะฆ่ามดชั่วตัวสำคัญ\n",
      "    เหมือนขับไสไล่เสือจากเคหา      รับหมาป่าเข้ามาเลยอาสัญ\n",
      "  ฝ่ายอ้องอุ้นยุแยกให้แตกกัน          ใช้สาวนั้นเป็นชนวนชื่นชวนใจ\n",
      "    พลันลิฉุยกุยกีกลับก่อเหตุ          ช่างอาเพศจริงหนาฟ้าร้องไห้\n",
      "  ต้องรบราฆ่าฟันจนบรรลัย           ฤๅหาใครค้ำชูกู้บรรลังก์ ฯ\n",
      "\n",
      "512 chars\n",
      "\n",
      "'    '19313 '๏'19273 ' '32 'แผ่น'65387 'ดิน'59548 'ฮ'19294 'ั'9630 '่น'44074 'เส'44118 'ื่อ'59224 'ม'9619 'โทร'59340 'ม'9619 'แสน'59506 'สัง'59466 'เว'44206 'ช'9605 '  '266 'พระ'59765 'ปก'43981 'เก'44234 'ศ'9624 'กอง'59203 'บู'44055 '๊'19252 'ก'9600 'ู้'44280 'ขึ้น'65482 'ใหม่'65670 '\\n  '3330 'สิ'44341 'บ'9614 'สอง'59212 'ก'9600 'ษ'9625 'ั'9630 'ตร'44233 'ิ'9633 'ย์'44168 'ก่อนหน้า'67817 'แล'43977 'ถ'9610 'ัด'44371 'ไป'44166 '       '44411 'สอง'59212 'องค์'65542 'ไซ'44230 'ร'9621 '้'9645 'โ'9640 'ง'9603 '่'9644 'เข'44372 'ลา'44270 'เบา'59406 'ปัญญา'66969 '\\n    '28422 'ทรง'59508 'นับ'59709 'ถือ'59623 'ขั'44062 'น'9613 'ที'44045 'เป็นที่'67659 'พ'9617 'ึ่ง'59675 '           '62421 'บ้าน'65582 'เมือง'66934 'จึง'59292 'วิ'44162 'ปริ'59758 'ต'9609 'เป็น'65412 'นัก'59295 'หน'44324 'า'9631 '\\n  '3330 'โฮ'44112 'จิ'44150 '๋'19277 'น'9613 'เรียก'66965 'ทัพ'59237 'ทั่ว'65376 'หัว'59753 'เมือง'66934 'มา'44374 '         '55322 'หมาย'65523 'จะ'44156 'ฆ่า'59718 'ม'9619 'ด'9608 'ชั่ว'65331 'ตัว'59590 'สำคัญ'66936 '\\n    '28422 'เหมือน'67437 'ขับ'59498 'ไ'9642 'ส'9626 'ไล่'59382 'เส'44118 'ือ'44160 'จาก'59606 'เค'44105 'หา'44302 '      '36286 'รับ'59686 'หม'44151 'า'9631 'ป่า'59667 'เข้ามา'67337 'เลย'59171 'อา'44095 'สัญ'59754 '\\n  '3330 'ฝ่าย'65336 'อ'9628 '้อง'59219 'อุ'44317 '้น'44214 'ยุ'44110 'แยก'59624 'ให้'59395 'แตก'59352 'กัน'59723 '          '59775 'ใช้'59561 'สาว'59634 'นั้น'65475 'เป็น'65412 'ชน'44275 'วน'43987 'ช'9605 'ื่'43337 'น'9613 'ชวน'59394 'ใจ'44146 '\\n    '28422 'พล'44218 'ัน'44279 'ลิ'44237 'ฉ'19281 'ุ'9636 'ยก'44129 'ุ'9636 'ยก'44129 'ี'9634 'กลับ'65528 'ก่อ'59167 'เหตุ'65519 '          '59775 'ช่าง'65454 'อา'44095 'เพศ'59601 'จริง'65419 'หน'44324 'า'9631 'ฟ้า'59577 'ร้อง'65381 'ไ'9642 'ห'9627 '้'9645 '\\n  '3330 'ต้อง'65494 'ร'9621 'บร'44391 'า'9631 'ฆ่า'59718 'ฟัน'59432 'จน'44097 'บรร'59463 'ล'9622 'ัย'44089 '           '62421 'ฤ'19292 'ๅ'19289 'หา'44302 'ใคร'59652 'ค'9602 '้ำ'44183 'ชู'44059 'ก'9600 'ู้'44280 'บรร'59463 'ลัง'59446 'ก'9600 '์'9646 ' '32 'ฯ'19283 \n",
      "\n",
      "193 tokens\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src2='''    ๏ แผ่นดินฮั่นเสื่อมโทรมแสนสังเวช  พระปกเกศกองบู๊กู้ขึ้นใหม่\n",
    "  สิบสองกษัตริย์ก่อนหน้าแลถัดไป       สององค์ไซร้โง่เขลาเบาปัญญา\n",
    "    ทรงนับถือขันทีเป็นที่พึ่ง           บ้านเมืองจึงวิปริตเป็นนักหนา\n",
    "  โฮจิ๋นเรียกทัพทั่วหัวเมืองมา         หมายจะฆ่ามดชั่วตัวสำคัญ\n",
    "    เหมือนขับไสไล่เสือจากเคหา      รับหมาป่าเข้ามาเลยอาสัญ\n",
    "  ฝ่ายอ้องอุ้นยุแยกให้แตกกัน          ใช้สาวนั้นเป็นชนวนชื่นชวนใจ\n",
    "    พลันลิฉุยกุยกีกลับก่อเหตุ          ช่างอาเพศจริงหนาฟ้าร้องไห้\n",
    "  ต้องรบราฆ่าฟันจนบรรลัย           ฤๅหาใครค้ำชูกู้บรรลังก์ ฯ'''\n",
    "print(src2)\n",
    "print(f'\\n{len(src2)} chars')\n",
    "tokens = TOKENIZER.encode(src2)\n",
    "assert TOKENIZER.decode(tokens) == src2\n",
    "print()\n",
    "TOKENIZER.printTokens(tokens)\n",
    "print(f'\\n{len(tokens)} tokens\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
